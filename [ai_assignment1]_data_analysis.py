# -*- coding: utf-8 -*-
"""[AI-Assignment1] Data Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EslDItZawoIFmOYWFVY07ThATflQsh0J
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ttest_1samp
from scipy.stats import ttest_ind

"""# Cars93 data
In this lab, we would like to explore data about 93 number of vehicles.

"""

df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')
df

"""# Data Statistics
Describe statistics of data using `describe()` method for numeric data (default mode.)


"""

df.describe()

"""For categorical data, specify `include` parametor as `'object'`.
(hint, refer [`pd.describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html))
"""

df.describe(include=object)

"""## Measuring skewness

First, make a numeric_columns by selecting only columns containing numerical data
"""

numericColumns = df.describe().columns
numericColumns

"""**[TODO]** Measure skewness for all numeric attribute and sort by value. (hint, please refer document of pandas [[ref](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html)].)"""

skewness = df[numericColumns].######.sort_values(ascending = False)
skewness

"""## Graphic visualization of skewness

**[TODO]** Select the Attributes that skewness value is the largest, smallest and the closet to zero.
* For zero skewness attribue, you can specify attribute. e.g., `df['RPM']`
"""

highSkewAttribute = df[##################]
lowSkewAttribute = df[##################]
zeroSkewAttribute = df['Length']

"""Draw plots. See how the distribution depends on the Skewness"""

f, axes = plt.subplots(3, 1, figsize=(10, 15))

# set the string
strInPlot = "Skewness: %f"

# Plot distplot (highSkew)
ax = axes[0]
sns.histplot(data=df, x=highSkewAttribute, color="skyblue", ax=ax, kde=True)

# Add legend
ax.text(x=0.97, y=0.97, transform=ax.transAxes, s=strInPlot % highSkewAttribute.skew(),\
    fontweight='demibold', fontsize=10, verticalalignment='top', horizontalalignment='right')

# Plot distplot (zeroSkew)
ax = axes[1]
sns.histplot(data=df, x=zeroSkewAttribute, color="khaki", ax=ax, kde=True)

# Add legend
ax.text(x=0.97, y=0.97, transform=ax.transAxes, s=strInPlot % zeroSkewAttribute.skew(),\
    fontweight='demibold', fontsize=10, verticalalignment='top', horizontalalignment='right')

# Plot distplot (lowSkew)
ax = axes[2]
sns.histplot(data=df, x=lowSkewAttribute, color="salmon", ax=ax, kde=True)

# Add legend
ax.text(x=0.97, y=0.97, transform=ax.transAxes, s=strInPlot % lowSkewAttribute.skew(),\
    fontweight='demibold', fontsize=10, verticalalignment='top', horizontalalignment='right')

plt.tight_layout()

"""## Correlation
**[TODO]** Select `Price`, `Horsepower`, `Rev.per.mile` attribte from dataframe, and compute `pearson` correlation value.
"""

## Compelete the code
selectedDataFrame = df[['Price', 'Horsepower', 'Passengers','Length', 'Weight']]
selectedDataFrame.##################

"""**[TODO]** Plot *pair plot*. The plot must satisify following conditions.

- Create a pair plot using the `targetvar` value above
"""

g = sns.##################
plt.show()

"""## Statistical Hypothesis Test
**[TODO]** We would like the test that is there a significant `Passengers`  difference between `small` and `midsize` type car.

Test our hypothesis with proper statistical test with siginificance level as 0.05.

If there is missing value (`nan`) in `pd.Series`, test will not be working properly.
"""

siginificantLevel = 0.05
smallCar = df[df['Type']=='Small']['Passengers'].dropna()
midsizeCar = df[df['Type']=='Midsize']['Passengers'].dropna()

stats, p = ##################
print('P-value', format(p, ".19f"))

if p < siginificantLevel:
  print("The Weight of the two types shows a significant difference.")
else:
  print("The Weight of the two types shows no significant difference.")

"""# Data Preprocessing

## Handling Outlier

**[TODO]** Exclude the outlier (cars) with too much expensive.
* Assume that `price` of outlier is greater than `Q3 + (1.5 * IQR)`.
"""

attribute = 'Price'

Q1 = df[attribute].quantile(.25)
Q3 = df[attribute].quantile(.75)
IQR = Q3 - Q1
outlierStep = 1.5 * IQR

filtered_df = df[##################]

"""Draw histogram of `price`."""

f, axes = plt.subplots(2, 1, figsize=(7, 5), sharex=True)

sns.histplot(data=df, x='Price', ax=axes[0], kde=True,
             bins=np.arange(0,80,5))
sns.histplot(data=filtered_df, x='Price', color='Red',
             ax=axes[1], kde=True, bins=np.arange(0,80,5))
f.tight_layout()

"""## Scaling
**[TODO]** Rescale the numeric attribute using z-score. You can use Scikit-learn or Pandas
"""

numericDf = df.select_dtypes(include='number')

from sklearn.preprocessing import StandardScaler

# create a scaler object
stdScaler = StandardScaler()

# fit and transform the data
std_df = pd.DataFrame(stdScaler.##################,
                          columns=numericDf.columns)

std_df.head()

"""## KNNImputer
**[TODO]** Impute the `std_df` with missing value with KNN imputation with parameter `n_neighbors = 2` and `weights` with `distance`.

"""

from sklearn.impute import KNNImputer

imp_KNN = KNNImputer(n_neighbors = 2, weights = 'distance')

impute_df = pd.DataFrame(imp_KNN.################,columns=std_df.columns)
impute_df

"""## Encoding
Filter categorical attribute and remove unnessary attribute using `.drop()`
* unnessary attribute: `Manufacturer`,	`Model`, `Make`
"""

catergorical_df = df.select_dtypes(exclude='number').drop(
    columns=['Manufacturer', 'Model', 'Make'])
catergorical_df.head()

"""**[TODO]** Encode remaining categorical attiribute into numeric attribute using label encoding."""

from sklearn.preprocessing import LabelEncoder

# create a encoder object
enc = LabelEncoder()

# create empthy dataframe
enc_df = pd.DataFrame()

# fill up data frame with encoded attribute using iteration
for col in catergorical_df.columns:
  enc_df[col] = enc.################)

enc_df.head()